# Aya-Expanse (Model Compression)

This directory includes code for our WMT 2025 paper, _Iterative Layer Pruning for Efficient Translation Inference_.

## Citation

If you find this paper or repository helpful, please cite the following paper.

```bib
@inproceedings{moslem-etal-2025-iterative,
    title = "Iterative Layer Pruning for Efficient Translation Inference",
    author = "Moslem, Yasmin and
        Farouq, Muhammad Hazim Al and
        Kelleher, D. John",
    booktitle = "Proceedings of the Tenth Conference on Translation (WMT 2025)",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
}
```

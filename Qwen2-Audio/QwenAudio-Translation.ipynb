{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datasets transformers hf_transfer huggingface_hub[hf_xet] librosa -q\n",
    "!pip3 install sacrebleu polars unbabel-comet -q\n",
    "!pip3 install bitsandbytes accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r model ymoslem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdad129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache_dir = \"/workspace/data/\"\n",
    "model_cache_dir = \"/workspace/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcdb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_lang_code = \"de\"\n",
    "# tgt_lang_code = \"zh\"\n",
    "# tgt_lang_code = \"ar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd288d7",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "acl6060_all = load_dataset(\"ymoslem/ACL-6060\",\n",
    "                           split=\"dev+eval\",\n",
    "                           cache_dir=data_cache_dir\n",
    "                          )\n",
    "acl6060_all = acl6060_all.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "acl6060 = acl6060_all.train_test_split(test_size=100, seed=0)\n",
    "\n",
    "acl6060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37be5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acl6060[\"test\"][\"text_en\"][0])\n",
    "print(acl6060[\"test\"][\"text_de\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3fa03",
   "metadata": {},
   "source": [
    "# Laod the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c314d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# model_name = \"Qwen/Qwen2-Audio-7B\"\n",
    "model_name = \"Qwen/Qwen2-Audio-7B-Instruct\"\n",
    "\n",
    "\n",
    "model = Qwen2AudioForConditionalGeneration.from_pretrained(model_name,\n",
    "                                                           cache_dir=model_cache_dir,\n",
    "                                                           # torch_dtype=torch.bfloat16,\n",
    "                                                          ).to(\"cuda\").eval()\n",
    "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "print(\"Model loaded:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.device.type == \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ab097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original config:\", model.generation_config)\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.temperature = None\n",
    "model.generation_config.top_k = None\n",
    "model.generation_config.top_p = None\n",
    "print(\"Modified config:\", model.generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e974e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(audio_array, audio_path, sr, language, shot=0, model_type=\"instruct\"):\n",
    "    \n",
    "    if model_type == \"base\":\n",
    "        text = f\"<|audio_bos|><|AUDIO|><|audio_eos|>Translate the English speech into {language}:\"\n",
    "\n",
    "    elif model_type == \"instruct\":\n",
    "        if shot == 1:\n",
    "            conversation = [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a professional translator.\"},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"As knowledge base we use Wikipedia. \\\n",
    "                    Translate the English speech into {language}:\"},\n",
    "                ]},\n",
    "                {\"role\": \"assistant\", \"content\": f\"Als Wissensbasis verwenden wir Wikipedia.\"},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"audio\", \"audio_url\": audio_path},  # just for formatting\n",
    "                    {\"type\": \"text\", \"text\": f\"Translate the English speech into {language}:\"},\n",
    "                ]},\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            conversation = [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a professional translator.\"},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"audio\", \"audio_url\": audio_path},\n",
    "                    {\"type\": \"text\", \"text\": f\"Translate the English speech into {language}:\"},\n",
    "                ]},\n",
    "            ]\n",
    "\n",
    "\n",
    "        text = processor.apply_chat_template(conversation,\n",
    "                                             add_generation_prompt=True,\n",
    "                                             tokenize=False,\n",
    "                                            )\n",
    "        # print(text)\n",
    "\n",
    "\n",
    "    inputs = processor(text=text,\n",
    "                       audio=audio_array,\n",
    "                       sampling_rate=sr,\n",
    "                       return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    #####\n",
    "    #first_input = inputs[\"input_ids\"][0].tolist()\n",
    "    #decoded_input = processor.tokenizer.decode(first_input, skip_special_tokens=False)\n",
    "    #print(f\"Decoded Input (First Row) :\\n{decoded_input}\")\n",
    "    #####\n",
    "    \n",
    "    max_length = 1024\n",
    "    generate_ids = model.generate(**inputs,\n",
    "                                  max_length=max_length,\n",
    "                                  do_sample=False,\n",
    "                                  repetition_penalty=1.0,\n",
    "                                  pad_token_id=processor.tokenizer.eos_token_id,\n",
    "                                 )\n",
    "    generate_ids = generate_ids[:, inputs.input_ids.size(1):]\n",
    "\n",
    "    response = processor.batch_decode(generate_ids,\n",
    "                                      skip_special_tokens=True,\n",
    "                                      clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shot = 0\n",
    "\n",
    "if model_name == \"Qwen/Qwen2-Audio-7B\":\n",
    "    model_type = \"base\"\n",
    "elif model_name == \"Qwen/Qwen2-Audio-7B-Instruct\":\n",
    "    model_type = \"instruct\"\n",
    "else:\n",
    "    model_type = \"instruct\"\n",
    "\n",
    "\n",
    "if tgt_lang_code == \"de\":\n",
    "    language = \"German\"\n",
    "elif tgt_lang_code == \"zh\":\n",
    "    language = \"Chinese\"\n",
    "elif tgt_lang_code == \"ar\":\n",
    "    language = \"Arabic\"\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported target language code: {tgt_lang_code}\")\n",
    "\n",
    "\n",
    "print(f\"{model_name=}\\n{model_type=}\\n{language=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e77403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "translations = []\n",
    "\n",
    "for segment in tqdm(acl6060[\"test\"]):\n",
    "    audios = [segment[\"audio\"][\"array\"]]\n",
    "    audio_path = segment[\"audio\"][\"path\"]\n",
    "    sr = segment[\"audio\"][\"sampling_rate\"]\n",
    "    \n",
    "    translation = translate(audios, audio_path, sr, language, shot, model_type)\n",
    "    translations.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(translations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25082014",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d5fdd",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7931b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = acl6060[\"test\"][f\"text_{tgt_lang_code}\"]\n",
    "source_sentences = acl6060[\"test\"][\"text_en\"]\n",
    "\n",
    "print(references[0])\n",
    "print(source_sentences[0])\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265524ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "bleu_tokenizer = \"zh\" if tgt_lang_code == \"zh\" else None\n",
    "\n",
    "# Calculate BLEU\n",
    "bleu = sacrebleu.corpus_bleu(translations, [references], tokenize=bleu_tokenizer)  # tokenize=\"zh\" for Chinese\n",
    "bleu = round(bleu.score, 2)\n",
    "print(\"BLEU:\", bleu)\n",
    "\n",
    "# Calculate ChrF++\n",
    "chrf = sacrebleu.corpus_chrf(translations, [references], word_order=2)\n",
    "chrf = round(chrf.score, 2)\n",
    "print(\"ChrF++:\", chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa51c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf2 = sacrebleu.corpus_chrf(translations, [references])\n",
    "chrf2 = round(chrf2.score, 2)\n",
    "print(\"ChrF:\", chrf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4288c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COMET\n",
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"wmt20-comet-da\")\n",
    "comet_model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate COMET\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"src\":source_sentences, \"mt\":translations, \"ref\":references})\n",
    "data = df.to_dict('records')\n",
    "\n",
    "seg_scores, sys_score = comet_model.predict(data, batch_size=128, gpus=1).values()\n",
    "comet = round(sys_score*100, 2)\n",
    "print(\"COMET:\", comet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "print(model_name)\n",
    "\n",
    "df = pl.DataFrame({\"BLEU\": bleu,\n",
    "                   \"ChrF++\": chrf,\n",
    "                   \"COMET\": comet,\n",
    "                   \"ChrF\": chrf2\n",
    "                  }\n",
    "                 )\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
